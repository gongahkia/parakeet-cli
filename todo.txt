



(B) Add unit tests for can_skip_row_group: in filter.rs #[cfg(test)] block test AND skip logic (either side false skips); OR skip logic (both sides false skips); NOT always returns false; Comparison skip for Int32/Int64 out-of-range values +test +core
(B) Add unit tests for identify_engine: in engine.rs #[cfg(test)] block test spark/pyarrow/duckdb/impala/hive/trino/flink/pandas/parquet-go/parquet4s created_by strings and unknown fallback returns empty hints +test +core
(B) Add integration test fixture: create tests/fixtures/ directory in parquet-lens-core with a minimal valid .parquet file; add integration test calling open_parquet_file, read_column_stats, aggregate_column_stats, score_column on the fixture +test +infra
(B) Add unit tests for detect_repair_suggestions: test zero row_groups returns empty Vec; test fragmentation trigger (>100 rgs avg <64MB); test high-null column suggestion (>50%); test large dict page suggestion +test +core
(B) Add parquet-lens filter subcommand: Commands::Filter { path: String, expr: String, output: Option<String>, limit: Option<usize> } that calls parse_predicate then filter_count and optionally exports matching rows to CSV +feature +cli
(B) Implement filter_rows fn in filter.rs: like filter_count but yields matching RecordBatches up to limit rows for use in filter subcommand CSV export path +feature +core
(B) Add parquet-lens schema subcommand: Commands::Schema { path: String, json: bool } that prints combined_schema as a plain table or JSON without full profiling for fast schema inspection in CI +feature +cli
(B) Fix full_scan_results not rendered in TUI: in render_column_detail when app.profiling_mode == FullScan and app.full_scan_results is non-empty display histogram bins and numeric profile data from the matching ColumnProfileResult for the selected column +bug +tui
(B) Add baseline_captured_at human-readable display: in render_baseline TUI view format app.baseline_captured_at unix timestamp using chrono::DateTime::from_timestamp as YYYY-MM-DD HH:MM:SS UTC string instead of raw seconds +feature +tui
(B) Add --json flag to Duplicates subcommand: emit DuplicateReport as serde_json to stdout when --json is passed +feature +cli
(B) Add --threshold flag to Duplicates subcommand: f64 percentage; exit non-zero if estimated_duplicate_pct exceeds threshold; enables use as pipeline quality gate +feature +cli
(B) Add --columns flag to Summary subcommand: Vec<String> via value_delimiter=','; filter column-level quality scores to named columns only in run_summary output +feature +cli
(B) Add --validate flag to Inspect subcommand: when set skip TUI launch; run detect_repair_suggestions, load_baseline_regressions, summarize_quality; print results to stdout; exit 0 if no issues exit 1 if issues found +feature +cli
(B) Add profile_timeseries output to export_json: include timeseries_profiles field in the JSON export document when timeseries data is non-empty +feature +core
(B) Add profile_nested_columns output to export_json: include nested_profiles field in JSON export document +feature +core
(B) Add repair_suggestions to export_json: include repair_suggestions field in JSON export document +feature +core
(B) Add row groups export to export_csv: write a second CSV file row_groups.csv to the same output directory containing RowGroupProfile data (index, row_count, total_byte_size, compression) +feature +core
(B) Fix filter_count column path comparison: replace schema_names string equality check with cm.column_descr().path_in_schema().string() comparison so nested column dot-notation paths are matched correctly +bug +core
(B) Add Decimal128 type support to build_mask in filter.rs: add downcast_ref::<Decimal128Array> branch with scale-aware f64 conversion for Eq/Ne/Lt/Le/Gt/Ge comparison ops +feature +core
(B) Add Date32/Date64 type support to build_mask in filter.rs: add downcast_ref::<Date32Array> and Date64Array branches comparing days-since-epoch as i64 values +feature +core
(B) Add BETWEEN predicate to parser: parse col BETWEEN a AND b emitting Predicate::And(Comparison(>=a), Comparison(<=b)) with full row-group pushdown via the two existing Comparison branches +feature +core
(B) Add NOT IN predicate to parser: parse col NOT IN (...) emitting Predicate::Not(In{...}); update can_skip_row_group to handle Not(In) conservatively returning false +feature +core
(B) Add SampleConfig seed documentation: add inline comment above SampleConfig struct and sample_row_groups fn stating seed: None produces non-deterministic results and CI pipelines must always pass --sample-seed for reproducibility +stability +core
(B) Move large-file threshold to config: replace hardcoded 1073741824 byte check in App::cycle_profiling_mode with config.profiling.large_file_threshold_bytes: u64 field (default 1073741824) defined in ProfilingConfig +refactor +common
(B) Add config.profiling.full_scan_timeout_secs: Option<u64> to ProfilingConfig; in run_tui spawn_blocking block use profile_columns_with_timeout instead of profile_columns when config value is Some +feature +common
(B) Add colorblind-safe theme: add colorblind variant to Theme::from_name that replaces red danger color with orange (#FF8C00) and green success with blue (#0080FF) +feature +tui
(B) Add --no-color flag to Summary subcommand: skip ANSI escape codes in pretty-format output when set; also honor NO_COLOR env var automatically via std::env::var("NO_COLOR").is_ok() at top of run_summary +feature +cli
(B) Add View::WatchLog to TUI: when --watch is active add W keybind rendering a scrollable list of last 20 reload events with timestamps and one-line diff summary (rows changed, schema changed flag) +feature +tui
(B) Add parquet-lens completions subcommand: Commands::Completions { shell: clap_complete::Shell } calling clap_complete::generate to stdout; add clap_complete to parquet-lens-tui Cargo.toml +feature +cli
(B) Fix session restore for FilterInput: verify App::to_session maps View::FilterInput to a serializable string and App::restore_from_session restores it; current code maps it to "overview" silently +bug +tui
(B) Add Makefile with standard targets: build (cargo build --release), test (cargo test --workspace), lint (cargo fmt --check && cargo clippy -- -D warnings), release (cargo build --release), install (cp target/release/parquet-lens /usr/local/bin/) +infra
(B) Add exit code documentation to check subcommand: add .long_about() on Commands::Check describing exit codes 0=clean 1=regressions-found 2=file-not-found for CI integration scripts +feature +cli
(B) Add --limit flag to Export subcommand: usize rows max; when set wrap the Arrow reader with .with_limit(limit) before exporting to CSV/JSON +feature +cli
(B) Add --format ndjson to Export subcommand: emit one JSON object per column stat as newline-delimited JSON for streaming CI tooling; add ndjson branch in run_export format match +feature +cli
(B) Fix sidebar_down/sidebar_up to operate on filtered index space: saturating_sub check max against filtered_column_indices().len() not raw column_count so navigation matches visible list +bug +tui
(B) Fix load_file_stats multi-file documentation: add doc comment on load_file_stats noting that returned meta is first-file-only and callers needing aggregate stats must use read_metadata_parallel separately +stability +core
(B) Add bloom filter size warning in detect_duplicates: if total_rows_estimate > 10_000_000 emit eprintln! warning before Bloom::new_for_fp_rate noting memory usage and recommending --exact flag +stability +core
(B) Wire profile_columns_with_timeout in run_tui spawn_blocking: when config.profiling.full_scan_timeout_secs is Some(t) call profile_columns_with_timeout with Duration::from_secs(t) instead of profile_columns +feature +tui
